{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data hosted from: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we will have convert the Base64 image to a numpy array of vectors of 28x28 = 784 numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.test.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.32941177  0.72549021  0.62352943  0.59215689  0.23529413  0.14117648\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.8705883   0.99607849  0.99607849  0.99607849  0.99607849\n",
      "  0.9450981   0.77647066  0.77647066  0.77647066  0.77647066  0.77647066\n",
      "  0.77647066  0.77647066  0.77647066  0.66666669  0.20392159  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.26274511  0.44705886  0.28235295\n",
      "  0.44705886  0.63921571  0.89019614  0.99607849  0.88235301  0.99607849\n",
      "  0.99607849  0.99607849  0.98039222  0.89803928  0.99607849  0.99607849\n",
      "  0.54901963  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.06666667  0.25882354\n",
      "  0.05490196  0.26274511  0.26274511  0.26274511  0.23137257  0.08235294\n",
      "  0.92549026  0.99607849  0.41568631  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.32549021  0.99215692  0.81960791  0.07058824  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.08627451  0.91372555  1.          0.32549021  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.50588238  0.99607849  0.9333334   0.17254902  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.23137257  0.97647065  0.99607849  0.24313727  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.52156866  0.99607849  0.73333335  0.01960784  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.03529412  0.80392164  0.97254908  0.227451    0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.49411768  0.99607849  0.71372551  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.29411766  0.98431379  0.94117653  0.22352943  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.07450981  0.86666673  0.99607849  0.65098041  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.01176471  0.7960785   0.99607849  0.8588236   0.13725491  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.14901961  0.99607849  0.99607849  0.3019608   0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.12156864  0.87843144  0.99607849  0.45098042  0.00392157  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.52156866  0.99607849  0.99607849  0.20392159  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.2392157\n",
      "  0.94901967  0.99607849  0.99607849  0.20392159  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.47450984  0.99607849  0.99607849  0.8588236   0.15686275  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.47450984  0.99607849  0.81176478  0.07058824  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(mnist.test.images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the label input by the user will have to be one hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add placeholder tensor/node of n inputs with indexes of 784 to graph. So any number of MNIST images, each flattened into a 784-dimensional vector, can be put into this placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weights and biases as tensorflow Varibles. Intializing the inital values as zeros. Since we are going to learn W and b, it doesn't matter very much what they initially are - according to tensorflow.\n",
    "\n",
    "Note the dimensions of W, we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors as the evidence for the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Tara/Documents/Emerging Technologies/Project/Emerging-Technologies-Assignment/rough_work/my_test_model.ckpt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "#Now, save the graph\n",
    "saver.save(sess, 'C:/Users/Tara/Documents/Emerging Technologies/Project/Emerging-Technologies-Assignment/rough_work/my_test_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "digit3 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03125, 0.0, 0.0, 0.0, 0.01171875, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.04296875, 0.42578125, 0.8671875, 0.97265625, 0.8984375, 0.6171875, 0.21875, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.35546875, 0.99609375, 0.83203125, 0.5703125, 0.75, 0.99609375, 0.99609375, 0.6015625, 0.0703125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.1640625, 0.4765625, 0.0078125, 0.0, 0.0, 0.1328125, 0.6015625, 0.99609375, 0.90234375, 0.234375, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0078125, 0.0, 0.0, 0.265625, 0.89453125, 0.97265625, 0.19140625, 0.00390625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.00390625, 0.0, 0.0, 0.0078125, 0.015625, 0.0, 0.1171875, 0.9375, 0.71875, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02734375, 0.0, 0.71875, 0.88671875, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01953125, 0.0, 0.12109375, 0.95703125, 0.7265625, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.015625, 0.015625, 0.0, 0.0, 0.1328125, 0.81640625, 0.9921875, 0.234375, 0.00390625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05859375, 0.51171875, 0.93359375, 0.9296875, 0.2578125, 0.0, 0.015625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.234375, 0.48828125, 0.63671875, 0.9296875, 0.99609375, 0.99609375, 0.828125, 0.46875, 0.21875, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.02734375, 0.5859375, 0.99609375, 0.99609375, 0.99609375, 0.828125, 0.7578125, 0.77734375, 0.8984375, 0.99609375, 0.99609375, 0.7421875, 0.12109375, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.1015625, 0.48046875, 0.4453125, 0.3125, 0.16015625, 0.0, 0.0, 0.0, 0.01953125, 0.13671875, 0.4921875, 0.99609375, 0.8125, 0.01953125, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.4140625, 0.99609375, 0.27734375, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.015625, 0.015625, 0.0078125, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.015625, 0.109375, 0.98828125, 0.4375, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.01171875, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.01171875, 0.07421875, 0.98828125, 0.44921875, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.00390625, 0.0, 0.0, 0.0, 0.0078125, 0.0234375, 0.0, 0.3984375, 0.99609375, 0.328125, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.3203125, 0.45703125, 0.015625, 0.0, 0.0, 0.01171875, 0.015625, 0.01171875, 0.0, 0.0, 0.3125, 0.99609375, 0.78125, 0.02734375, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.015625, 0.84375, 0.99609375, 0.83203125, 0.3671875, 0.06640625, 0.0, 0.0, 0.0, 0.10546875, 0.47265625, 0.99609375, 0.83984375, 0.1015625, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.171875, 0.50390625, 0.8984375, 0.99609375, 0.9453125, 0.5390625, 0.39453125, 0.68359375, 0.99609375, 0.99609375, 0.71875, 0.08203125, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.33203125, 0.7734375, 0.99609375, 0.99609375, 0.98828125, 0.6484375, 0.2734375, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.015625, 0.0, 0.0, 0.0, 0.13671875, 0.17578125, 0.06640625, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.00390625, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "digit2 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.0078125, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.08203125, 0.140625, 0.15625, 0.15625, 0.02734375, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.0, 0.0, 0.25, 0.59765625, 0.84765625, 0.99609375, 0.99609375, 0.99609375, 0.99609375, 0.90625, 0.36328125, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.37109375, 0.8359375, 0.99609375, 0.99609375, 0.80859375, 0.53515625, 0.4140625, 0.3515625, 0.43359375, 0.828125, 0.99609375, 0.2578125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.06640625, 0.5859375, 0.99609375, 0.87109375, 0.43359375, 0.1015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0390625, 0.9296875, 0.75390625, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.2578125, 0.99609375, 0.6171875, 0.015625, 0.0, 0.0, 0.00390625, 0.015625, 0.015625, 0.015625, 0.03125, 0.0, 0.65625, 0.97265625, 0.0234375, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17578125, 0.0, 0.0, 0.015625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.00390625, 0.53125, 0.99609375, 0.05078125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.00390625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.53515625, 0.99609375, 0.046875, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.8125, 0.88671875, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.00390625, 0.171875, 0.99609375, 0.4921875, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.66796875, 0.98828125, 0.11328125, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.2578125, 0.99609375, 0.5703125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.08203125, 0.8984375, 0.8828125, 0.0546875, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.0078125, 0.734375, 0.99609375, 0.2265625, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.62890625, 0.99609375, 0.41015625, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.03125, 0.6328125, 0.99609375, 0.4765625, 0.0, 0.015625, 0.00390625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.1015625, 0.78515625, 0.99609375, 0.48828125, 0.0, 0.0234375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.01171875, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.22265625, 0.89453125, 0.98828125, 0.30078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.94921875, 0.921875, 0.42578125, 0.29296875, 0.53515625, 0.6953125, 0.80078125, 0.84375, 0.8984375, 0.90625, 0.90234375, 0.90234375, 0.80859375, 0.484375, 0.25, 0.08203125, 0.0, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.05078125, 0.3671875, 0.9375, 0.99609375, 0.9921875, 0.99609375, 0.99609375, 0.99609375, 0.92578125, 0.828125, 0.74609375, 0.6953125, 0.65625, 0.66015625, 0.66015625, 0.8671875, 0.99609375, 0.99609375, 0.26171875, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.32421875, 0.99609375, 0.99609375, 0.91796875, 0.7265625, 0.40625, 0.2421875, 0.09765625, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14453125, 0.30859375, 0.0234375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.12109375, 0.4765625, 0.36328125, 0.09375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.01171875, 0.015625, 0.015625, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.015625, 0.01171875, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0078125, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.015625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "digit = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.01171875, 0.01171875, 0.015625, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.1875, 0.12890625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0078125, 0.3828125, 0.84765625, 0.99609375, 0.99609375, 0.84375, 0.75, 0.73828125, 0.68359375, 0.49609375, 0.15625, 0.0, 0.0078125, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.18359375, 0.7890625, 0.99609375, 0.84765625, 0.4609375, 0.67578125, 0.8203125, 0.83203125, 0.83984375, 0.921875, 0.99609375, 0.9921875, 0.40234375, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.234375, 0.94921875, 0.96484375, 0.40234375, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.26953125, 0.796875, 0.99609375, 0.6640625, 0.08203125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0, 0.29296875, 0.99609375, 0.87890625, 0.1484375, 0.0, 0.00390625, 0.015625, 0.0078125, 0.00390625, 0.00390625, 0.00390625, 0.0, 0.0, 0.00390625, 0.48828125, 0.99609375, 0.9375, 0.33984375, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.109375, 0.9609375, 0.87890625, 0.12109375, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.00390625, 0.0, 0.234375, 0.82421875, 0.99609375, 0.40625, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.6484375, 0.99609375, 0.17578125, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.03515625, 0.74609375, 0.99609375, 0.28125, 0.0, 0.01171875, 0.0, 0.0, 0.0078125, 0.0, 0.09375, 0.99609375, 0.62890625, 0.0, 0.01953125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.05078125, 0.87109375, 0.8671875, 0.01171875, 0.00390625, 0.00390625, 0.0, 0.01171875, 0.0, 0.20703125, 0.99609375, 0.3046875, 0.00390625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01953125, 0.0, 0.40625, 0.99609375, 0.24609375, 0.0, 0.01171875, 0.0, 0.01171875, 0.0, 0.19140625, 0.99609375, 0.29296875, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.10546875, 0.9921875, 0.4765625, 0.0, 0.015625, 0.0, 0.01171875, 0.0, 0.1953125, 0.99609375, 0.3515625, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.0, 0.06640625, 0.99609375, 0.4765625, 0.0, 0.015625, 0.0, 0.00390625, 0.0, 0.078125, 0.9921875, 0.57421875, 0.00390625, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.1015625, 0.9921875, 0.4609375, 0.0, 0.015625, 0.0, 0.0, 0.00390625, 0.0, 0.8359375, 0.8515625, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.37890625, 0.99609375, 0.296875, 0.0, 0.015625, 0.0, 0.0, 0.015625, 0.0, 0.45703125, 0.99609375, 0.26953125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.00390625, 0.0703125, 0.9140625, 0.85546875, 0.02734375, 0.00390625, 0.00390625, 0.0, 0.0, 0.00390625, 0.00390625, 0.078125, 0.875, 0.91015625, 0.08984375, 0.0078125, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0078125, 0.0, 0.6875, 0.99609375, 0.21875, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.2109375, 0.99609375, 0.68359375, 0.0, 0.01171875, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.0, 0.0, 0.62890625, 0.99609375, 0.4453125, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.015625, 0.0, 0.5, 0.99609375, 0.4921875, 0.0, 0.0, 0.0, 0.01171875, 0.015625, 0.015625, 0.015625, 0.01171875, 0.0, 0.0, 0.1328125, 0.65234375, 0.99609375, 0.51171875, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.01171875, 0.00390625, 0.640625, 0.99609375, 0.76953125, 0.2265625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0546875, 0.55859375, 0.99609375, 0.99609375, 0.5078125, 0.0, 0.015625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.0, 0.44140625, 0.95703125, 0.99609375, 0.8984375, 0.71875, 0.6328125, 0.6328125, 0.6328125, 0.70703125, 0.9609375, 0.99609375, 0.64453125, 0.203125, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.0, 0.078125, 0.47265625, 0.7265625, 0.8984375, 0.921875, 0.921875, 0.921875, 0.90625, 0.6953125, 0.3046875, 0.0, 0.0, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0078125, 0.0078125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.015625, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01171875, 0.01171875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.00390625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "digit1 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.9921875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.515625, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99609375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.64581642e-01   8.90585682e-07   7.47328997e-01   3.47225703e-02\n",
      "    1.14971016e-07   4.55679558e-02   3.01265032e-07   2.80277345e-06\n",
      "    7.79458694e-03   1.46497555e-07]]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {x: [digit]}\n",
    "classification = y.eval(feed_dict) \n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24b016fd0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN predicted 3\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from random import randint\n",
    "#num = randint(0, mnist.test.images.shape[0])\n",
    "#img = mnist.test.images[num]\n",
    "\n",
    "classification = sess.run(tf.argmax(y, 1), feed_dict={x: [digit3]})\n",
    "plt.imshow(digit3.reshape(28, 28), cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print('NN predicted', classification[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
